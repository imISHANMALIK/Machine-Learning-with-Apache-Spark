{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3tdCUHa8vkX",
        "outputId": "a07500bb-389b-44a6-c0f2-9d0b246342c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=17dcbd9a704554da69b185018948fc251eace625f4bbe4ba7b0cef6f857e804a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "(33, 325.3333333333333)\n",
            "(26, 242.05882352941177)\n",
            "(55, 295.53846153846155)\n",
            "(40, 250.8235294117647)\n",
            "(68, 269.6)\n",
            "(59, 220.0)\n",
            "(37, 249.33333333333334)\n",
            "(54, 278.0769230769231)\n",
            "(38, 193.53333333333333)\n",
            "(27, 228.125)\n",
            "(53, 222.85714285714286)\n",
            "(57, 258.8333333333333)\n",
            "(56, 306.6666666666667)\n",
            "(43, 230.57142857142858)\n",
            "(36, 246.6)\n",
            "(22, 206.42857142857142)\n",
            "(35, 211.625)\n",
            "(45, 309.53846153846155)\n",
            "(60, 202.71428571428572)\n",
            "(67, 214.625)\n",
            "(19, 213.27272727272728)\n",
            "(30, 235.8181818181818)\n",
            "(51, 302.14285714285717)\n",
            "(25, 197.45454545454547)\n",
            "(21, 350.875)\n",
            "(42, 303.5)\n",
            "(49, 184.66666666666666)\n",
            "(48, 281.4)\n",
            "(50, 254.6)\n",
            "(39, 169.28571428571428)\n",
            "(32, 207.9090909090909)\n",
            "(58, 116.54545454545455)\n",
            "(64, 281.3333333333333)\n",
            "(31, 267.25)\n",
            "(52, 340.6363636363636)\n",
            "(24, 233.8)\n",
            "(20, 165.0)\n",
            "(62, 220.76923076923077)\n",
            "(41, 268.55555555555554)\n",
            "(44, 282.1666666666667)\n",
            "(69, 235.2)\n",
            "(65, 298.2)\n",
            "(61, 256.22222222222223)\n",
            "(28, 209.1)\n",
            "(66, 276.44444444444446)\n",
            "(46, 223.69230769230768)\n",
            "(29, 215.91666666666666)\n",
            "(18, 343.375)\n",
            "(47, 233.22222222222223)\n",
            "(34, 245.5)\n",
            "(63, 384.0)\n",
            "(23, 246.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"FriendsByAge\")\n",
        "sc = SparkContext(conf = conf)\n",
        "\n",
        "def parseLine(line):\n",
        "    fields = line.split(',')\n",
        "    age = int(fields[2])\n",
        "    numFriends = int(fields[3])\n",
        "    return (age, numFriends)\n",
        "\n",
        "lines = sc.textFile(\"file:///content/fakefriends.csv\")\n",
        "rdd = lines.map(parseLine)\n",
        "totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])\n",
        "results = averagesByAge.collect()\n",
        "for result in results:\n",
        "    print(result)"
      ]
    }
  ]
}